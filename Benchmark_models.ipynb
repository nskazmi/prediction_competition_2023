{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97aebc4f",
   "metadata": {},
   "source": [
    "# *Benchmark Models Generation - to provide a baseline for the prediction competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e7ba263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import os\n",
    "from functools import partial\n",
    "import random\n",
    "import getpass #use when the user is a root user to get the name from the username and not 'root'\n",
    "\n",
    "\n",
    "\n",
    "# Views 3\n",
    "# These imports require a certificate, these won't work without the certificate\n",
    "import views_runs\n",
    "from viewser.operations import fetch\n",
    "from views_forecasts.extensions import *\n",
    "from viewser import Queryset, Column\n",
    "\n",
    "#All the functions are in the BenchmarkModels.py file, importing them to use them in this notebook\n",
    "from BenchmarkModels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fdc723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropbox path set to /Users/noorainkazmi/Dropbox (ViEWS)/ViEWS/\n",
      "Overleaf path set to /Users/noorainkazmi/Dropbox (ViEWS)/Apps/Overleaf/Prediction competition 2023/\n"
     ]
    }
   ],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002' # This is used when using ensemble prediction functions later in the notebook - pd.DataFrame.forecasts.read_store(cm_ensemble_name, run=dev_id)[stepcols]\n",
    "run_id = 'Fatalities002'\n",
    "EndOfHistory = 508\n",
    "get_future = False\n",
    "\n",
    "#username = os.getlogin() # This is your PC's username to use Dropbox - install Dropbox App to avail this functionality - returns 'root' for default user\n",
    "username = getpass.getuser() # Same as above - use this to get the name of the user\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for - Creates a list from 1 to 36 with 36 numbers\n",
    "\n",
    "fi_steps = [1,3,6,12,36] # this list is never used\n",
    "\n",
    "\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,456)} #Calibration partition - the numbers are month codes 121 - January 1990 \n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(457,504)} #Test partition\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(505,512)} #Future Prediction partition\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict}) # calling a function from viewser\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict}) # calling a function from viewser\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict}) # calling a function from viewser\n",
    "\n",
    "Mydropbox = f'/Users/{username}/Dropbox (ViEWS)/ViEWS/' #download Dropbox app\n",
    "overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/Prediction competition 2023/' #download Overleaf app\n",
    "\n",
    "\n",
    "print('Dropbox path set to',Mydropbox)\n",
    "print('Overleaf path set to',overleafpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1871166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'noorainkazmi'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(os.getlogin())\n",
    "import getpass\n",
    "getpass.getuser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fc756",
   "metadata": {},
   "source": [
    "# From here we start creating benchmark models - we will create 1000 or 100 draws or probabilty distribution around the point predictions from the viewser prediction ensemble function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1983d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ln_ged_sb_dep', 'step_pred_3', 'step_pred_4', 'step_pred_5', 'step_pred_6', 'step_pred_7', 'step_pred_8', 'step_pred_9', 'step_pred_10', 'step_pred_11', 'step_pred_12', 'step_pred_13', 'step_pred_14']\n"
     ]
    }
   ],
   "source": [
    "# Benchmark model parameters \n",
    "filepath = Mydropbox + 'Prediction_competition_2023/'\n",
    "\n",
    "year_list = [2018, 2019, 2020, 2021] # Creating predictions for 4 years\n",
    "draws_cm = 1000 # 1000 draws at cm level\n",
    "draws_pgm = 100 # 100 draws at pgm level\n",
    "\n",
    "steps = [3,4,5,6,7,8,9,10,11,12,13,14] #list of steps to create a list of names below\n",
    "stepcols = ['ln_ged_sb_dep']\n",
    "for step in steps:\n",
    "    stepcols.append('step_pred_' + str(step))\n",
    "print(stepcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b82eebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/noorainkazmi/Dropbox (ViEWS)/ViEWS/Prediction_competition_2023/'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a9c1ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a787408",
   "metadata": {},
   "source": [
    "# CM Level Benchmark Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753bec8",
   "metadata": {},
   "source": [
    "### Based on ensemble from viewser prediction function; the point prediciton are expanded using a Poisson draw with mean=variance=\\hat{y}_{it} Mean and variance are equal. They are equal to the point prediction here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3d09e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_46_cm_ensemble_genetic_test.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.12410915e-02  5.60521179e-03 -1.66970564e-04  4.61977907e-02\n",
      "  1.26977494e-02  1.26318393e-02  7.84479735e-03  1.21005169e-02\n",
      "  3.27088766e-02  7.29877831e-03  1.23359747e-02  4.23541715e-03\n",
      "  1.40422565e+00  2.36443872e-03  8.69316514e-03  1.39654856e-02\n",
      "  3.30625671e-03  7.59595732e-03  8.43953965e-03  7.72571714e-03\n",
      "  7.85325904e-03  1.27282516e-02  2.49365692e-02  4.08350905e-03\n",
      "  7.54581282e-03  1.60515202e-03  3.00996490e+00  6.29210408e-03\n",
      "  1.18088904e-02  2.40926748e-03  1.31888510e-02  2.88629097e-03\n",
      "  4.70333657e-03  1.96972197e-03  1.68757503e-03  9.57411296e-03\n",
      "  1.04596789e-02  1.82975922e-03  2.46246298e-02  1.34293792e-01\n",
      "  9.28361815e-02  1.13209432e-03  9.76249567e-03  3.24694764e-01\n",
      "  2.23659909e+00  3.05789995e-02  1.09342519e-02  2.74613989e+01\n",
      "  5.45396014e-02  6.77114332e-03  1.39346500e-02  5.60422468e-02\n",
      "  2.71887040e-01  1.05692021e+00  7.81926053e-03  1.09575515e+03\n",
      "  4.76947081e-01  1.00463404e-02  2.88254046e-02  3.70418300e+00\n",
      "  2.23617316e-02  2.50438951e+00  9.51036276e+00  2.05369851e+00\n",
      "  7.18521922e-01  1.29871091e-01  3.63071091e-02  1.26897089e-02\n",
      "  1.12871868e+01  1.98531134e+02  9.43053370e-03  3.16936985e-02\n",
      "  1.11364265e-04 -1.00691828e-03  3.25276103e-04  3.76882573e-01\n",
      " -1.00377328e-03  5.84063533e-03  6.96106668e-02  6.18357114e-03\n",
      "  1.99505622e-02  1.74537549e-02  2.18731733e+00  2.93316480e+01\n",
      "  1.04313574e-02 -2.26015270e-03  1.76896223e-02  1.02812026e-02\n",
      "  2.23603146e-02  2.71905019e-03  2.83969015e-05  1.43200354e-01\n",
      "  3.74484706e-01  2.40756512e-02  1.05237832e-02  1.40376302e-02\n",
      "  7.59021781e-03 -1.52471551e-03  2.76179862e-02  1.01034672e-03\n",
      "  4.89153205e-04 -5.81084114e-04  3.03254902e-03  3.12436307e+01\n",
      "  1.42037273e-02  3.00755266e-02  7.01772699e+02  9.16499902e-03\n",
      "  1.43422499e-02  2.28290377e-02  1.94372177e+02  1.39661188e-01\n",
      "  1.74822526e+00  4.38608772e-02  1.81911304e+00  2.42653576e-02\n",
      "  1.78363011e-02  1.54772431e+00  2.03802147e-02  2.40899272e+03\n",
      "  1.00794442e-02  4.97871242e-02  1.06013494e+02  2.92968498e-02\n",
      "  1.97216626e+00  2.91881582e-02  2.52751347e-03  1.41324935e-02\n",
      "  2.37135883e-02  1.73011280e-03  2.43474915e+02  1.43938475e-02\n",
      "  1.84395445e-02  2.85417774e-02  8.51634598e+00  3.41059801e+00\n",
      "  3.05684588e-02  2.38469482e-03  2.20387765e-03  1.03612651e-02\n",
      "  6.61022567e-01  6.74830816e-02  3.63531797e-02  2.26591474e-02\n",
      "  6.77487635e-03  9.95438850e-03  1.94578519e-02  4.02130620e-01\n",
      "  5.71670754e-03  1.50689971e-02  4.23684105e-01  4.78451023e-01\n",
      "  2.78564431e+02  9.80959108e-03  2.90517792e-02 -1.51265485e-04\n",
      "  1.48804853e-02  4.79056862e-02  8.54060181e-03  1.07580686e-02\n",
      "  1.38030935e-03  1.32496043e-02  1.28457507e-02  1.03770885e-02\n",
      "  1.26655794e-02  1.26920267e-02  1.12252288e-02  1.62012281e-02\n",
      "  1.81372688e-01  1.18126730e-02  1.73981884e-01  6.99829173e-02\n",
      "  1.41230131e-02  4.90747174e-01  6.63098088e+00  1.44498144e+00\n",
      "  1.68802310e+00  6.38481000e+03  4.22935937e+01  1.07567948e+02\n",
      "  1.58419485e-03  7.29580932e-03  5.26219906e-03  2.79140078e-02\n",
      "  6.53547227e-02  5.86802576e+00  2.02001102e-02  5.63626266e-03\n",
      "  5.04329116e-02  6.61428970e+00  1.07584643e+01]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 7.92719193e-03  7.74045857e-03  7.04930636e-02  1.75590545e-01\n",
      "  1.27119828e-02  1.26983701e-02  9.03755850e-03  1.44060197e-02\n",
      "  1.43914424e+00  7.66862074e-03  1.47243263e-02  4.68687858e-03\n",
      "  1.16425151e-01  2.67555239e-03  5.57892954e-02  1.44241950e-01\n",
      "  3.70161573e-03  7.69970104e-03  9.04122180e-03  7.79222109e-03\n",
      "  7.79577998e-03  1.31047418e-02  2.45480222e-02  2.36337725e-02\n",
      "  7.63091517e-03  4.07829947e-02  9.22153891e+00  6.81764096e-03\n",
      "  1.07898088e-02  2.11531639e-01  3.07980700e-01  5.10069907e-03\n",
      "  2.25937312e-03  7.59889385e-03  1.74645012e-03  9.56928468e-03\n",
      "  1.01185281e-02  1.76208863e-03  1.74130335e-02  9.57652096e-02\n",
      "  5.96572077e-02  1.21132177e-03  6.39597458e-03  2.28902956e-01\n",
      "  6.79099905e+00  4.08705451e-02  6.88636567e-03  2.10095318e+01\n",
      "  8.87779904e-02  5.65452273e-03  9.72285819e-03  6.42030012e-02\n",
      "  1.36980223e-01  4.88947911e+00  1.36549722e-02  2.59906386e+02\n",
      "  2.71059095e-01  8.13114656e-03  3.42805039e-02  1.90543486e+00\n",
      "  1.78721271e-02  1.74723063e+00  9.05628566e+01  2.74741700e+00\n",
      "  2.25358186e+00  1.34192928e-01  3.49254389e-02  1.26868228e-02\n",
      "  2.14615794e+00  2.08991022e+02  9.70588223e-03  3.13816996e-02\n",
      "  1.24356520e-03  4.15916280e-04  3.29076622e-04  3.54063238e-01\n",
      " -8.25382238e-04  5.88081009e-03  7.28291010e-02  6.19102284e-03\n",
      "  2.00156970e-02  1.25160258e-02  3.59622867e-01  2.11527964e+01\n",
      "  1.03676853e-02 -1.99048321e-03  1.76827600e-02  9.95166395e-03\n",
      "  2.32950376e-02  5.66465633e-04  2.92056516e-05  3.15630975e-01\n",
      "  3.12809139e-01  8.82110032e-03  1.01426154e-02  1.37720314e-02\n",
      "  6.23553242e-03 -1.11734874e-03  3.38706724e-02  1.02051097e-03\n",
      "  6.69325652e-04  5.00917032e-04  1.54825264e-03  4.12963035e+01\n",
      "  1.41392229e-02  2.90553198e-02  3.78429433e+02  8.54104508e-03\n",
      "  2.68316838e-02  2.89110386e-02  3.89589968e+02  7.89441358e-01\n",
      "  1.16284205e+00  1.74021918e-02  3.35016833e+00  1.73179914e-02\n",
      "  1.26632403e-02  1.23880348e+00  1.83030746e-02  2.08873678e+03\n",
      "  6.44688469e-03  2.16981704e-02  2.85149753e+01  7.59008184e-02\n",
      "  1.26577682e+00  2.37056927e-02  6.65580970e-02  1.18357222e-02\n",
      "  2.51866552e-02  1.84201563e-03  2.79831894e+01  1.21797932e-02\n",
      "  2.37903087e-02  3.40910783e-02  6.84903809e+00  3.15980989e+00\n",
      "  4.36580173e-02  2.08415362e-03  2.22478083e-03  1.17727512e-02\n",
      "  6.85391322e-01  4.79028770e-02  5.20993459e-02  2.94045045e-02\n",
      "  6.72270021e-03  1.77000882e-03  2.64082234e-02  2.06658483e+00\n",
      "  8.65613391e-03  2.12071698e-02  3.92356522e-01  3.01608435e-01\n",
      "  9.17004931e+01  9.47489166e-03  3.00003176e-02 -1.52287738e-04\n",
      "  1.50584214e-02  2.28117900e-02  8.25815670e-03  1.08473994e-02\n",
      "  3.08974710e-03  1.32458905e-02  1.28456482e-02  1.12368939e-02\n",
      "  1.34372201e-02  1.26919679e-02  1.15850229e-02  1.03249688e-02\n",
      "  1.90300089e-01  1.17294968e-02  1.12271226e-01  7.70020338e-02\n",
      "  1.36560899e-02  6.69720495e-01  4.41405762e+00  8.94656690e+00\n",
      "  2.25422696e+00  1.17074971e+03  5.42441492e+01  1.35532339e+02\n",
      " -1.04674074e-03  7.44714286e-03  8.05632798e-03  2.35767402e-02\n",
      "  4.62637570e-02  2.48734571e+00  1.49435470e-02  1.24929317e-02\n",
      "  4.17900761e-02  1.28801029e+01  5.65858880e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.22364646e-02  7.30296806e-03  6.96836269e-02  2.23517054e-01\n",
      "  1.26423128e-02  1.27189021e-02  8.45959739e-03  1.27095787e-02\n",
      "  1.26879435e+00  7.86426901e-03  7.27639267e-02  7.75853779e-03\n",
      "  3.98379095e-02  2.48240795e-03  7.47257247e-02  5.51823833e-01\n",
      "  3.35310201e-03  7.71296460e-03  7.52550374e-03  7.84915215e-03\n",
      "  7.79499630e-03  1.49298053e-02  2.54275626e-02  6.99229044e-02\n",
      "  7.69483602e-03  4.34014318e-02  9.83605830e+00  1.86015336e-02\n",
      "  1.08822826e-02  6.26703304e-02  1.55023065e-01  1.03535036e-02\n",
      "  2.39828167e-03  7.59811381e-03  1.74645012e-03  9.54181965e-03\n",
      "  1.00120041e-02  1.04890636e-01  9.72826895e-03  8.53307784e-02\n",
      "  5.17339895e-02  4.04742430e-03  7.18485412e-03  2.03103823e-01\n",
      "  2.76694636e+01  4.27092345e-02  6.38055607e-03  2.83606963e+01\n",
      "  4.28239881e-02  5.43122382e-03  8.77743348e-03  3.65433542e-02\n",
      "  9.50508072e-02  3.15505619e+00  9.84056733e-03  1.39720855e+02\n",
      "  8.09468625e-02  6.54459541e-03  3.55906558e-02  1.10114154e+00\n",
      "  1.56623445e-02  1.59751139e+00  6.03385449e+01  2.41452146e+00\n",
      "  1.83999288e+00  1.17518762e-01  3.36191913e-02  1.26077304e-02\n",
      "  5.35939538e+00  2.05821996e+02  1.06500025e-02  3.88047435e-02\n",
      "  1.52555418e-03 -4.33919104e-04  1.27886342e-02  3.77100681e-01\n",
      " -1.08584598e-03  5.87785079e-03  1.37701540e-01  6.20628641e-03\n",
      "  1.44106810e-02  1.45133033e-02  1.78573012e-01  2.79099210e+01\n",
      "  1.12331776e-02 -2.10777933e-03  1.70304767e-02  1.21036672e-02\n",
      "  1.69418662e-02  5.20486252e-04  7.35831492e-05  2.17144797e-01\n",
      "  2.49006921e-01  8.45875425e-03  6.57905228e-03  1.33143529e-02\n",
      "  4.59955597e-03 -2.08805512e-03  3.34984337e-02  9.41678583e-04\n",
      "  4.12346838e-04  2.22809152e-04  1.99027070e-03  3.70723891e+01\n",
      "  1.35779473e-02  3.02037481e-02  2.46772400e+02  5.55274556e-02\n",
      "  2.59744834e-02  3.71558951e-02  1.83663454e+02  1.12720155e+00\n",
      "  1.56815521e+00  1.48815658e-02  1.84067721e+00  1.90003186e-02\n",
      "  1.72777519e-02  3.05621517e-01  1.77728980e-02  2.40543623e+03\n",
      "  8.36814311e-03  1.78942916e-02  2.23774487e+01  3.45249752e-01\n",
      "  3.40053390e-01  2.40666809e-02  4.36292058e-03  1.23829368e-02\n",
      "  2.43080949e-02  1.79624527e-03  1.84632785e+01  1.25171607e-02\n",
      "  1.68714768e-02  3.21229564e-02  2.53037722e+01  9.83494235e-01\n",
      "  5.95583032e-02  2.07920100e-03  2.23032623e-03  1.30407166e-02\n",
      "  2.37335406e+00  1.29231110e+00  5.41916754e-02  6.42060627e-02\n",
      "  7.37754426e-03  2.88514943e-03  3.67315371e-02  2.70610097e+01\n",
      "  8.33295767e-03  3.11153176e-02  2.69100015e-01  1.43983600e-01\n",
      "  5.74915915e+01  9.59775757e-03  3.54010777e-02  1.13825839e-03\n",
      "  1.57257564e-02  3.83910247e-02  8.99371821e-03  1.10229114e-02\n",
      "  9.88139414e-03  8.34268415e-02  1.28299321e-02  1.04725804e-02\n",
      "  1.35015819e-02  1.26761995e-02  1.13682743e-02  1.02584945e-02\n",
      "  1.74636847e-01  1.17984597e-02  5.06992240e-02  8.99385393e-02\n",
      "  1.27408846e-02  1.65025428e+00  9.30282422e+01  2.82739799e+00\n",
      "  1.43765380e+00  1.42732355e+03  5.67617468e+01  8.48371764e+01\n",
      " -1.19784650e-03  1.46112729e-02  5.99788688e-03  2.18756489e-02\n",
      "  3.09701487e-02  5.03777881e+00  1.74074747e-02  4.60129205e-03\n",
      "  3.56083678e-02  1.71119698e+00  6.38526368e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 6.70203057e-03  5.13366143e-03  3.16184992e-02  1.83161295e-01\n",
      "  1.27019173e-02  1.28109612e-02  9.21409509e-03  1.88424678e-02\n",
      "  1.33844914e+00  1.00386766e-02  6.01266312e-02  5.81923311e-03\n",
      "  2.78098783e-01  2.37165135e-03  6.57622841e-02  4.76207182e-01\n",
      "  3.42053849e-03  7.64172346e-03  7.50605109e-03  7.78189744e-03\n",
      "  7.80305371e-03  2.32841834e-02  1.94349248e-01  6.27023092e-02\n",
      "  7.58978992e-03  3.54738725e-02  4.39362882e+00  7.60924321e-03\n",
      "  9.33761920e-03  8.38326338e-02  7.67266352e-02  5.50705296e-03\n",
      "  2.07017299e-03  7.63749110e-03  7.59764989e-03  9.63832340e-03\n",
      "  9.97081515e-03  4.08497366e-02  1.72119424e-02  1.64166126e-01\n",
      "  4.04079759e-02  3.00759982e-03  7.45897566e-03  1.94603627e-01\n",
      "  7.08845400e+00  4.80707802e-02  6.47763684e-03  4.89361072e+01\n",
      "  4.00634955e-02  5.46519889e-03  9.01347174e-03  5.88251117e-02\n",
      "  8.16688519e-02  1.38725626e+00  8.03884632e-03  1.16182594e+02\n",
      "  8.96336122e-02  6.28882543e-03  2.47042463e-02  3.54582676e+00\n",
      "  1.43122078e-02  1.46601753e+00  1.94589940e+01  1.73316629e+00\n",
      "  7.79861854e-01  1.19183267e-01  3.04132648e-02  1.26435207e-02\n",
      "  2.36087157e+00  2.29697310e+02  9.52321385e-03  3.27741704e-02\n",
      "  4.69881467e-04  1.10747506e-04  3.33956700e-04  3.62186607e-01\n",
      " -1.00955419e-03  5.88138747e-03  1.25286954e-02  5.83129288e-03\n",
      "  1.45063941e-02  1.58566837e-02  1.30508573e+00  1.96968713e+01\n",
      "  1.43447802e-02 -1.55587232e-03  1.72658289e-02  7.90029511e-03\n",
      "  1.18127554e-02  9.72324324e-04  4.55775204e-05  1.95147818e-02\n",
      "  5.47329633e-02  8.82670082e-03  6.86797935e-03  1.28866770e-02\n",
      "  1.72379463e-02 -1.38732515e-03  2.35363360e-02  7.77155142e-04\n",
      "  4.92995105e-04  2.10478583e-04  2.21460433e-03  1.89952816e+01\n",
      "  1.29308914e-02  3.11563189e-02  5.47852717e+02  4.03907933e-02\n",
      "  1.96081947e-02  3.00040079e-02  2.70556491e+02  1.40444513e+00\n",
      "  2.60738339e+01  1.34180941e-02  4.89103904e+00  1.79996460e-02\n",
      "  1.71369307e-02  2.68927403e-01  1.72924525e-02  2.20867288e+03\n",
      "  1.50155021e-03  1.66983856e-02  4.24136047e+01  1.07615955e-01\n",
      "  9.66704561e-01  3.07862329e-02  1.25220800e-02  1.15609923e-02\n",
      "  1.93566450e-02  2.18539628e-03  1.98027423e+01  1.18345701e-02\n",
      "  1.54480282e-02  3.42226078e-02  1.54282635e+01  3.33818886e+00\n",
      "  6.55868515e-02  2.09328269e-03  2.23002740e-03  9.79241628e-03\n",
      "  2.53555229e+00  2.61424223e-01  6.93686424e-02  4.35978311e-02\n",
      "  8.18878182e-03  7.99585293e-04  3.38179593e-02  6.90301309e+01\n",
      "  1.39446781e-02  2.80412016e-02  7.87117556e-01  8.31644260e-02\n",
      "  1.55272050e+02  9.95483702e-03  3.85503604e-02  8.91916389e-04\n",
      "  1.50584719e-02  4.09360731e-01  8.70452877e-03  1.10320998e-02\n",
      "  4.04155534e-03  5.81710201e-02  1.28680527e-02  1.22079521e-02\n",
      "  1.09837343e-02  1.27249742e-02  1.13645870e-02  1.01235161e-02\n",
      "  1.60733938e-01  1.18075649e-02  5.59366281e-02  3.53148186e-02\n",
      "  1.33393162e-02  2.15513074e+00  2.20078488e+00  5.60421471e+00\n",
      "  5.93642117e-01  8.55814543e+02  3.80301291e+01  9.73935778e+01\n",
      " -1.09765763e-03  4.84972700e-03  1.43964447e-03  1.94050494e-02\n",
      "  6.07272510e-02  2.25622131e+00  1.52623961e+00  7.73616845e-03\n",
      "  3.38871557e-02  4.34423172e+00  2.36159013e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/Users/noorainkazmi/Documents/GitHub/prediction_competition_2023/BenchmarkModels.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n"
     ]
    }
   ],
   "source": [
    "# Assembling benchmark based on VIEWS ensemble predictions\n",
    "sc_predictions_ensemble = [] #empty list to store the predictions\n",
    "cm_ensemble_name = 'cm_ensemble_genetic_test' #internal name to feed to the viewser function\n",
    "    \n",
    "ensemble_df = pd.DataFrame.forecasts.read_store(cm_ensemble_name, run=dev_id)[stepcols] #need viewser certificate, read_store is a function \n",
    "ensemble_df.head() # check the ensemble dataframe\n",
    "\n",
    "for year in year_list: # year_list = [2018, 2019, 2020, 2021]\n",
    "    sc_dict = {\n",
    "        'year': year,\n",
    "        'prediction_df': extract_sc_predictions(year=year,ss_predictions=ensemble_df)\n",
    "    } # creating a dictionary year-wise\n",
    "    sc_predictions_ensemble.append(sc_dict) # appended the dictionary to the empty list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eff35e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting actuals from the ensemble\n",
    "actuals=np.expm1(ensemble_df['ln_ged_sb_dep'].fillna(0)) #using numpy Calculate exp(x) - 1 for all elements in the array on one column of pandas\n",
    "actuals_by_year=[] #year list\n",
    "for year in year_list:\n",
    "    actuals_dict = {\n",
    "        'year': year,\n",
    "        'actuals_df': extract_year(year=year,df=actuals) #extract info from actuals year-wise, see BenchmarkModels.py for the function details\n",
    "    }\n",
    "    actuals_by_year.append(actuals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6078f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals.isna().sum() #finds the number of missing values in the dataframe - actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3c16d",
   "metadata": {},
   "source": [
    "### CM - Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8d17741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "Mean and std of original predictions, all rows:\n",
      "        prediction\n",
      "count  2292.000000\n",
      "mean     46.288810\n",
      "std     334.649615\n",
      "min       0.000000\n",
      "25%       0.017667\n",
      "50%       0.037432\n",
      "75%       0.190760\n",
      "max    6384.809995\n",
      "Mean and std of expanded predictions, all rows:\n",
      "        outcome\n",
      "count   2292000\n",
      "unique     4162\n",
      "top           0\n",
      "freq    1763985\n",
      "Mean and std of original predictions, one cm:\n",
      "count     2.00000\n",
      "unique    2.00000\n",
      "top       1.05692\n",
      "freq      1.00000\n",
      "Name: (457, 57), dtype: float64\n",
      "Mean and std of expanded predictions, one cm:\n",
      "        outcome\n",
      "count      1000\n",
      "unique        7\n",
      "top           1\n",
      "freq        365\n",
      "Variance: outcome    1.063038\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>draw</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">457</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         outcome\n",
       "month_id country_id draw        \n",
       "457      1          0          0\n",
       "                    1          0\n",
       "                    2          0\n",
       "                    3          0\n",
       "                    4          0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expanding by drawing n draws from \"Poisson distribution\"   \n",
    "\n",
    "for year_record in sc_predictions_ensemble:\n",
    "    print(year_record['year'])\n",
    "    df = year_record.get('prediction_df')\n",
    "    year_record['expanded_df_poisson'] = expanded_df_poisson(df,ndraws=1000,level='cm') #create a new column in the \n",
    "    \n",
    "describe_expanded(df=sc_predictions_ensemble[0]['prediction_df'], df_expanded=sc_predictions_ensemble[0]['expanded_df_poisson'], month=457, country=57)  #comparing actuals with expanded dataframe   #month 457 - Jan 2018 and country 57? why this particularly? \n",
    "\n",
    "sc_predictions_ensemble[0]['expanded_df_poisson'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64296ad",
   "metadata": {},
   "source": [
    "### CM - Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "280eba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and std of original predictions, all rows:\n",
      "       ln_ged_sb_dep\n",
      "count    2292.000000\n",
      "mean       24.078098\n",
      "std       188.941513\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max      2964.000000\n",
      "Mean and std of expanded predictions, all rows:\n",
      "            outcome\n",
      "count  2.292000e+06\n",
      "mean   2.389554e+01\n",
      "std    1.882091e+02\n",
      "min    0.000000e+00\n",
      "25%    0.000000e+00\n",
      "50%    0.000000e+00\n",
      "75%    0.000000e+00\n",
      "max    2.963000e+03\n",
      "Mean and std of original predictions, one cm:\n",
      "count     2.0\n",
      "unique    2.0\n",
      "top       0.0\n",
      "freq      1.0\n",
      "Name: (457, 57), dtype: float64\n",
      "Mean and std of expanded predictions, one cm:\n",
      "           outcome\n",
      "count  1000.000000\n",
      "mean     24.818000\n",
      "std     179.287894\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.000000\n",
      "max    2690.000000\n",
      "Variance: outcome    32144.149025\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>draw</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">457</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          outcome\n",
       "month_id country_id draw         \n",
       "457      1          0           0\n",
       "                    1           9\n",
       "                    2           0\n",
       "                    3           0\n",
       "                    4          42"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expanding by drawing n draws bootstrap-fashion from the actuals   \n",
    "\n",
    "for year_record in actuals_by_year:\n",
    "#    print(year_record)\n",
    "    df = year_record.get('actuals_df')\n",
    "    \n",
    "    year_record['expanded_df_bootstrap'] = expanded_df_bootstrap(df,ndraws=1000,draw_from=df['ln_ged_sb_dep'],level='cm')\n",
    "    \n",
    "describe_expanded(df=actuals_by_year[0]['actuals_df'], df_expanded=actuals_by_year[0]['expanded_df_bootstrap'], month=457, country=57) #comparing actuals with expanded dataframe   #month 457 - Jan 2018 and country 57? why this particularly?\n",
    "\n",
    "actuals_by_year[0]['expanded_df_bootstrap'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cfcb7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month_id  country_id\n",
       "457       1              0.0\n",
       "          2              0.0\n",
       "          3              0.0\n",
       "          4              0.0\n",
       "          5              0.0\n",
       "                        ... \n",
       "468       242            0.0\n",
       "          243            0.0\n",
       "          244            0.0\n",
       "          245            9.0\n",
       "          246           39.0\n",
       "Name: ln_ged_sb_dep, Length: 2292, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals_by_year[0]['actuals_df']['ln_ged_sb_dep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34b77fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped = pd.DataFrame(actuals_by_year[0]['expanded_df_bootstrap']['outcome']).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2b9747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.292000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.389554e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.882091e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.963000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            outcome\n",
       "count  2.292000e+06\n",
       "mean   2.389554e+01\n",
       "std    1.882091e+02\n",
       "min    0.000000e+00\n",
       "25%    0.000000e+00\n",
       "50%    0.000000e+00\n",
       "75%    0.000000e+00\n",
       "max    2.963000e+03"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrapped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48a3c5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2292.000000\n",
       "mean       24.078098\n",
       "std       188.941513\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max      2964.000000\n",
       "Name: ln_ged_sb_dep, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals_by_year[0]['actuals_df']['ln_ged_sb_dep'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb9366d",
   "metadata": {},
   "source": [
    "### CM - Constituent Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bd551",
   "metadata": {},
   "source": [
    "#### Based on constituent models\n",
    "\n",
    "Short version, 20 models: \n",
    "1 \"draw\"\n",
    "from each of 20 constituent models\n",
    "\n",
    "Plus version with 45 draws from Poisson distribution for each model.\n",
    "\n",
    "Possibly obsolete:\n",
    "Long version, 440 models:\n",
    "20 \"draws\" from each of 22 constituent models, using predictions for adjacent steps (from s-4 to s+6). Some duplications to weight the most proximate steps more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "989b764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_baseline_rf baseline002\n",
      "1 fatalities002_conflicthistory_rf conflict_ln\n",
      "2 fatalities002_conflicthistory_gbm conflict_ln\n",
      "3 fatalities002_conflicthistory_hurdle_lgb conflict_ln\n",
      "4 fatalities002_conflicthistory_long_xgb conflictlong_ln\n",
      "5 fatalities002_vdem_hurdle_xgb vdem_short\n",
      "6 fatalities002_wdi_rf wdi_short\n",
      "7 fatalities002_topics_rf topics_002\n",
      "8 fatalities002_topics_xgb topics_002\n",
      "9 fatalities002_topics_hurdle_lgb topics_002\n",
      "10 fatalities002_joint_broad_rf joint_broad\n",
      "11 fatalities002_joint_broad_hurdle_rf joint_broad\n",
      "12 fatalities002_joint_narrow_xgb joint_narrow\n",
      "13 fatalities002_joint_narrow_hurdle_xgb joint_narrow\n",
      "14 fatalities002_joint_narrow_hurdle_lgb joint_narrow\n",
      "15 fatalities002_all_pca3_xgb all_features\n",
      "16 fatalities002_aquastat_rf aquastat\n",
      "17 fatalities002_faostat_rf faostat\n",
      "18 fatalities002_faoprices_rf faoprices\n",
      "19 fatalities002_imfweo_rf imfweo\n",
      "0 fatalities002_baseline_rf\n",
      "pr_46_cm_fatalities002_baseline_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_baseline_rf_test.parquet\n",
      "1 fatalities002_conflicthistory_rf\n",
      "pr_46_cm_fatalities002_conflicthistory_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_conflicthistory_rf_test.parquet\n",
      "2 fatalities002_conflicthistory_gbm\n",
      "pr_46_cm_fatalities002_conflicthistory_gbm_calib.parquet\n",
      "pr_46_cm_fatalities002_conflicthistory_gbm_test.parquet\n",
      "3 fatalities002_conflicthistory_hurdle_lgb\n",
      "pr_46_cm_fatalities002_conflicthistory_hurdle_lgb_calib.parquet\n",
      "pr_46_cm_fatalities002_conflicthistory_hurdle_lgb_test.parquet\n",
      "4 fatalities002_conflicthistory_long_xgb\n",
      "pr_46_cm_fatalities002_conflicthistory_long_xgb_calib.parquet\n",
      "pr_46_cm_fatalities002_conflicthistory_long_xgb_test.parquet\n",
      "5 fatalities002_vdem_hurdle_xgb\n",
      "pr_46_cm_fatalities002_vdem_hurdle_xgb_calib.parquet\n",
      "pr_46_cm_fatalities002_vdem_hurdle_xgb_test.parquet\n",
      "6 fatalities002_wdi_rf\n",
      "pr_46_cm_fatalities002_wdi_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_wdi_rf_test.parquet\n",
      "7 fatalities002_topics_rf\n",
      "pr_46_cm_fatalities002_topics_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_topics_rf_test.parquet\n",
      "8 fatalities002_topics_xgb\n",
      "pr_46_cm_fatalities002_topics_xgb_calib.parquet\n",
      "pr_46_cm_fatalities002_topics_xgb_test.parquet\n",
      "9 fatalities002_topics_hurdle_lgb\n",
      "pr_46_cm_fatalities002_topics_hurdle_lgb_calib.parquet\n",
      "pr_46_cm_fatalities002_topics_hurdle_lgb_test.parquet\n",
      "10 fatalities002_joint_broad_rf\n",
      "pr_46_cm_fatalities002_joint_broad_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_joint_broad_rf_test.parquet\n",
      "11 fatalities002_joint_broad_hurdle_rf\n",
      "pr_46_cm_fatalities002_joint_broad_hurdle_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_joint_broad_hurdle_rf_test.parquet\n",
      "12 fatalities002_joint_narrow_xgb\n",
      "pr_46_cm_fatalities002_joint_narrow_xgb_calib.parquet\n",
      "pr_46_cm_fatalities002_joint_narrow_xgb_test.parquet\n",
      "13 fatalities002_joint_narrow_hurdle_xgb\n",
      "pr_46_cm_fatalities002_joint_narrow_hurdle_xgb_calib.parquet\n",
      "pr_46_cm_fatalities002_joint_narrow_hurdle_xgb_test.parquet\n",
      "14 fatalities002_joint_narrow_hurdle_lgb\n",
      "pr_46_cm_fatalities002_joint_narrow_hurdle_lgb_calib.parquet\n",
      "pr_46_cm_fatalities002_joint_narrow_hurdle_lgb_test.parquet\n",
      "15 fatalities002_all_pca3_xgb\n",
      "pr_46_cm_fatalities002_all_pca3_xgb_calib.parquet\n",
      "pr_46_cm_fatalities002_all_pca3_xgb_test.parquet\n",
      "16 fatalities002_aquastat_rf\n",
      "pr_46_cm_fatalities002_aquastat_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_aquastat_rf_test.parquet\n",
      "17 fatalities002_faostat_rf\n",
      "pr_46_cm_fatalities002_faostat_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_faostat_rf_test.parquet\n",
      "18 fatalities002_faoprices_rf\n",
      "pr_46_cm_fatalities002_faoprices_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_faoprices_rf_test.parquet\n",
      "19 fatalities002_imfweo_rf\n",
      "pr_46_cm_fatalities002_imfweo_rf_calib.parquet\n",
      "pr_46_cm_fatalities002_imfweo_rf_test.parquet\n",
      "All done\n",
      "Calibrating models\n",
      "fatalities002_baseline_rf\n",
      "fatalities002_conflicthistory_rf\n",
      "fatalities002_conflicthistory_gbm\n",
      "fatalities002_conflicthistory_hurdle_lgb\n",
      "fatalities002_conflicthistory_long_xgb\n",
      "fatalities002_vdem_hurdle_xgb\n",
      "fatalities002_wdi_rf\n",
      "fatalities002_topics_rf\n",
      "fatalities002_topics_xgb\n",
      "fatalities002_topics_hurdle_lgb\n",
      "fatalities002_joint_broad_rf\n",
      "fatalities002_joint_broad_hurdle_rf\n",
      "fatalities002_joint_narrow_xgb\n",
      "fatalities002_joint_narrow_hurdle_xgb\n",
      "fatalities002_joint_narrow_hurdle_lgb\n",
      "fatalities002_all_pca3_xgb\n",
      "fatalities002_aquastat_rf\n",
      "fatalities002_faostat_rf\n",
      "fatalities002_faoprices_rf\n",
      "fatalities002_imfweo_rf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fatalities002 stuff - contains the list of the current fatalities002 ensemble models\n",
    "\n",
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "level = 'cm'\n",
    "ModelList_cm = DefineEnsembleModels(level)\n",
    "ModelList_cm = ModelList_cm[0:20] # Drop Markov models\n",
    "\n",
    "i = 0\n",
    "for model in ModelList_cm:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1\n",
    "\n",
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "\n",
    "ModelList_cm = RetrieveStoredPredictions(ModelList_cm, steps, EndOfHistory, dev_id, level, get_future)\n",
    "\n",
    "ModelList_cm = CalibratePredictions(ModelList_cm, EndOfHistory, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling benchmark based on VIEWS constituent model predictions\n",
    "draws_per_model = np.floor_divide(draws_cm,len(ModelList_cm))\n",
    "\n",
    "for model in ModelList_cm:\n",
    "    print(model['modelname'])\n",
    "\n",
    "    model['sc_predictions_constituent'] = []\n",
    "\n",
    "    for year in year_list:\n",
    "        sc_dict = {\n",
    "            'year': year,\n",
    "            'prediction_df': extract_sc_predictions(year=year,ss_predictions=model['predictions_test_df'])\n",
    "        }\n",
    "        model['sc_predictions_constituent'].append(sc_dict)\n",
    "\n",
    "    # Expanding by drawing n draws from Poisson distribution   \n",
    "    for year_record in model['sc_predictions_constituent']:\n",
    "        print(year_record['year'])\n",
    "        df = year_record.get('prediction_df')\n",
    "        year_record['expanded_df'] = expanded_df(df,ndraws=50,level='cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4793e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_predictions_constituent = []\n",
    "\n",
    "for year in year_list:\n",
    "    print(year)\n",
    "    print(ModelList_cm[0]['modelname'])\n",
    "    merged_expanded_df = ModelList_cm[0]['sc_predictions_constituent'][year-2018]['expanded_df']\n",
    "#    print(expanded_df.describe())\n",
    "    i = 0\n",
    "    for model in ModelList_cm[1:19]:\n",
    "        print(model['modelname'])\n",
    "        merged_expanded_df = pd.concat([merged_expanded_df,model['sc_predictions_constituent'][year-2018]['expanded_df']])\n",
    "#        print(expanded_df.describe())\n",
    "        \n",
    "    sc_dict = {\n",
    "        'year': year,\n",
    "        'expanded_df': merged_expanded_df\n",
    "    }\n",
    "    sc_predictions_constituent.append(sc_dict)\n",
    "    i = i + 1\n",
    "       \n",
    "#sc_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247cf23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21d26142",
   "metadata": {},
   "source": [
    "### Saving the CM benchmark models & actuals in separate Parquet files in Dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['ensemble','constituent']\n",
    "i = 0\n",
    "for bm_model in [sc_predictions_ensemble,sc_predictions_constituent]:\n",
    "    for record in bm_model:\n",
    "        year_record = record # First part of record list is list of yearly predictions, second is string name for benchmark model\n",
    "        print(year_record['year'])\n",
    "        filename = filepath + 'bm_cm_' + model_names[i] + '_expanded_' + str(year_record['year']) + '.parquet'\n",
    "        print(filename)\n",
    "        year_record['expanded_df'].to_parquet(filename) #save to file\n",
    "    i = i + 1\n",
    "\n",
    "# Dataframe with actuals\n",
    "df_actuals = pd.DataFrame(ModelList_cm[0]['predictions_test_df']['ln_ged_sb_dep'])\n",
    "cm_actuals = df_actuals\n",
    "cm_actuals['ged_sb'] = np.expm1(cm_actuals['ln_ged_sb_dep'])\n",
    "cm_actuals.drop(columns=['ln_ged_sb_dep'], inplace=True)\n",
    "print(cm_actuals.head())\n",
    "print(cm_actuals.tail())\n",
    "print(cm_actuals.describe())\n",
    "\n",
    "\n",
    "# Annual dataframes with actuals, saved to disk\n",
    "for year in year_list:\n",
    "    first_month = (year - 1980)*12 + 1\n",
    "    last_month = (year - 1980 + 1)*12\n",
    "    df_annual = cm_actuals.loc[first_month:last_month]\n",
    "    filename = filepath + 'cm_actuals_' + str(year) + '.parquet'\n",
    "    print(year, first_month, last_month, filename)\n",
    "    print(df_annual.head())\n",
    "    df_annual.to_parquet(filename)\n",
    "# For all four years\n",
    "filename = filepath + 'cm_actuals_allyears.parquet' #save to file\n",
    "cm_actuals.to_parquet(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f670157",
   "metadata": {},
   "source": [
    "# PGM Level Benchmark Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77004edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling benchmark based on VIEWS ensemble predictions\n",
    "sc_predictions_ensemble_pgm = []\n",
    "# any old pgm data\n",
    "pgm_ensemble_name = 'pgm_ensemble_cm_calib_test'\n",
    "    \n",
    "ensemble_pgm_df = pd.DataFrame.forecasts.read_store(pgm_ensemble_name, run=dev_id)[stepcols]\n",
    "ensemble_pgm_df.head()\n",
    "\n",
    "for year in year_list[0:3]:\n",
    "    sc_dict = {\n",
    "        'year': year,\n",
    "        'prediction_df': extract_sc_predictions(year=year,ss_predictions=ensemble_pgm_df)\n",
    "    }\n",
    "    sc_predictions_ensemble_pgm.append(sc_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding by drawing n draws from Poisson distribution   \n",
    "function_with_draws = partial(sample_poisson_row, ndraws=500) #here 500 draws are used?\n",
    "for year_record in sc_predictions_ensemble_pgm:\n",
    "    print(year_record['year'])\n",
    "    df = year_record.get('prediction_df')\n",
    "    year_record['expanded_df'] = expanded_df(df,ndraws=500,level='pgm')\n",
    "\n",
    "#describe_expanded(df=sc_predictions_ensemble_pgm[0]['prediction_df'], df_expanded=sc_predictions_ensemble_pgm[0]['expanded_df'], month=457, country=57)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba9569",
   "metadata": {},
   "source": [
    "# Saving the pgm models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['ensemble','constituent']\n",
    "i = 0\n",
    "for bm_model in [sc_predictions_ensemble_pgm]:\n",
    "    for record in bm_model:\n",
    "        year_record = record # First part of record list is list of yearly predictions, second is string name for benchmark model\n",
    "        print(year_record['year'])\n",
    "        filename = filepath + 'bm_pgm_' + model_names[i] + '_expanded_' + str(year_record['year']) + '.parquet'\n",
    "        print(filename)\n",
    "        year_record['expanded_df'].to_parquet(filename)\n",
    "    i = i + 1\n",
    "\n",
    "# Dataframe with actuals\n",
    "df_actuals = pd.DataFrame(ensemble_pgm_df)\n",
    "pgm_actuals = df_actuals\n",
    "pgm_actuals['ged_sb'] = np.expm1(pgm_actuals['ln_ged_sb_dep'])\n",
    "pgm_actuals.drop(columns=['ln_ged_sb_dep'], inplace=True)\n",
    "print(pgm_actuals.head())\n",
    "print(pgm_actuals.tail())\n",
    "print(pgm_actuals.describe())\n",
    "\n",
    "\n",
    "# Annual dataframes with actuals, saved to disk\n",
    "for year in year_list:\n",
    "    first_month = (year - 1980)*12 + 1\n",
    "    last_month = (year - 1980 + 1)*12\n",
    "    df_annual = pgm_actuals.loc[first_month:last_month]\n",
    "    filename = filepath + 'cm_actuals_' + str(year) + '.parquet'\n",
    "    print(year, first_month, last_month, filename)\n",
    "    print(df_annual.head())\n",
    "    df_annual.to_parquet(filename)\n",
    "# For all four years\n",
    "filename = filepath + 'pgm_actuals_allyears.parquet'\n",
    "pgm_actuals.to_parquet(filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d686ea",
   "metadata": {},
   "source": [
    "# Old stuff from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_data = sc_predictions_ensemble[0].get('prediction_df')\n",
    "test_data['draws'] = test_data.apply(function_with_draws, axis=1)\n",
    "test_data.explode('draws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fef3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test version, cm\n",
    "test_data = sc_predictions_ensemble[0].get('prediction_df')\n",
    "test_data['draws'] = test_data.apply(function_with_draws, axis=1)\n",
    "td = test_data.explode('draws')\n",
    "td.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6bcac5",
   "metadata": {},
   "source": [
    "# Old cm stuff from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e0952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe118d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_df_cm(df, draw):\n",
    "    ''' Drops steps we will not need in the benchmark model. \n",
    "    Another round of drops are done below '''\n",
    "    steps_to_drop = ['ln_ged_sb_dep','step_pred_25','step_pred_26','step_pred_27','step_pred_28','step_pred_29','step_pred_30',\n",
    "                     'step_pred_31','step_pred_32','step_pred_33','step_pred_34','step_pred_35','step_pred_36',]\n",
    "    df = df.drop(steps_to_drop,axis=1)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['draw'] = draw\n",
    "    df_long = pd.wide_to_long(df, 'step_pred_', i = ['month_id', 'country_id'], j = 'step')\n",
    "    df_long.reset_index(inplace=True)\n",
    "    df_long.set_index(['month_id','country_id','step','draw'],inplace=True)\n",
    "    return(df_long)\n",
    "    \n",
    "model_draw = 0\n",
    "df = ModelList_cm[model_draw]['predictions_test_df'].copy()\n",
    "df_cm_results_long = reshape_df_cm(df,model_draw)\n",
    "print('Starting with model/draw',model_draw, model['modelname'])\n",
    "print(df_cm_results_long.describe())\n",
    "print(df_cm_results_long.head())\n",
    "\n",
    "\n",
    "for model in ModelList_cm[1:]:\n",
    "    model_draw += 1\n",
    "    print('Appending model/draw',model_draw, model['modelname'])\n",
    "    df = ModelList_cm[model_draw]['predictions_test_df'].copy()\n",
    "    df_reshaped = reshape_df_cm(df,model_draw)\n",
    "    df_cm_results_long = pd.concat([df_cm_results_long ,df_reshaped], axis=0)\n",
    "    \n",
    "\n",
    "df_cm_results_long['prediction'] = np.round_(np.expm1(df_cm_results_long['step_pred_'])).astype('int32')\n",
    "df_cm_results_long.drop(columns=['step_pred_'], inplace=True)\n",
    "# Results file in long format\n",
    "print(df_cm_results_long.describe())\n",
    "print(df_cm_results_long.tail())\n",
    "\n",
    "print(df_cm_results_long.loc[492].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1871a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_final_extended = df_cm_results_long.copy()\n",
    "\n",
    "def make_dfcopy_cm(df_in, step, shifted_step, repetition):\n",
    "    ''' Makes a 'copy' of the df with a shifted step '''\n",
    "#    print(step, shifted_step, repetition)\n",
    "    df = pd.DataFrame(df_in[df_in.index.get_level_values('step').isin([shifted_step])]).copy()\n",
    "    df.reset_index(inplace = True)\n",
    "    df['step'].replace(shifted_step, step, inplace = True)\n",
    "#    print(df.describe())\n",
    "    df['draw'] = (df['draw'] + len(ModelList_cm) * repetition)\n",
    "#    print(df.describe())\n",
    "    df.set_index(['month_id', 'country_id', 'step', 'draw'], inplace=True)\n",
    "    return(df)\n",
    "    \n",
    "df_list_steps = []\n",
    "df_list_steps.append(df_cm_results_long)\n",
    "for step in range(3,14+1):     \n",
    "#    print(80*'*')\n",
    "    print('Step', step)\n",
    "    df = pd.DataFrame(df_cm_results_long[df_cm_results_long.index.get_level_values('step').isin([step])])\n",
    "#    print(df.head(3))\n",
    "    repetition = 1\n",
    "    df_list = []\n",
    "    for shift in [(-4,2),(-3,4),(-2,5),(-1,6),(0,6),(1,5),(2,4),(3,3),(4,2),(5,2),(6,2),(7,1),(8,1),(9,1)]:\n",
    "        for copy in range(1,shift[1]+1):\n",
    "            shifted_step = step+shift[0]\n",
    "            if shifted_step < 1:\n",
    "                shifted_step = step\n",
    "            step_list = [shifted_step]\n",
    "            df = make_dfcopy_cm(df_in = df_cm_results_long,step = step, shifted_step = shifted_step, repetition = repetition)\n",
    "            df_list.append(df)\n",
    "            repetition += 1\n",
    "    df_cm_temp = pd.concat(df_list)\n",
    "    df_list_steps.append(df_cm_temp)\n",
    "\n",
    "df_cm_final_extended = pd.concat(df_list_steps)\n",
    "#df.reorder_levels(['month_id','country_id','steps','draw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb476c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_ss48_to_sc12(df, level,firstmonth,years):\n",
    "    ''' Converts a dataframe in long format from one including all VIEWS ss predictions \n",
    "        into a set of dataframes containing only sc predictions for 12 months '''\n",
    "    df_list = []\n",
    "    for year in range(1,years+1):\n",
    "        this_firstmonth = firstmonth + (year-1)*12\n",
    "        print(year, this_firstmonth)\n",
    "#        this_df = df.query(f'month_id >= {this_firstmonth} and month_id <= {this_firstmonth+12-1}')\n",
    "        month_df_list = []\n",
    "        for step in range(3,14+1):\n",
    "            select_month = this_firstmonth + step - 3\n",
    "#            print('retaining month',select_month,'step',step)\n",
    "            month_df = df.query(f'month_id == {select_month} and step == {step}')\n",
    "            month_df_list.append(month_df)\n",
    "        year_df = pd.concat(month_df_list)\n",
    "        df_list.append(year_df)\n",
    "    return(df_list)\n",
    "\n",
    "    \n",
    "cm_ensemble_predictions = from_ss48_to_sc12(df_cm_final_extended,'cm',445,4)\n",
    "\n",
    "cm_ensemble_predictions[1].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d92db",
   "metadata": {},
   "source": [
    "### cm last historical values benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c89361",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = (Queryset(\"benchmark_cm\", \"country_month\")\n",
    "\n",
    "   # target variable\n",
    "   .with_column(Column(\"ged_sb\", from_table=\"ged2_cm\", from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.fill()\n",
    "                .transform.missing.replace_na()\n",
    "                )\n",
    "\n",
    "\n",
    "   .with_theme(\"benchmark\")\n",
    "   .describe(\"\"\"Data for empirical benchmark model, cm level\n",
    "\n",
    "\n",
    "            \"\"\")\n",
    "   )\n",
    "\n",
    "#queryset = Queryset(\"name\", \"loa\") # if not already defined\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_cm\"\n",
    "lags=range(1,65)\n",
    "for lag in lags: \n",
    "    qs = qs.with_column(Column(column+'_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                       )\n",
    "df_cm_historical_values = qs.publish().fetch()\n",
    "df_cm_historical_values = df_cm_historical_values.loc[445:492]\n",
    "\n",
    "df_cm_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafdd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictions for test partition\n",
    "number_of_lags = 45\n",
    "maxstep = 14\n",
    "df_list_bystep = []\n",
    "for step in range(3,maxstep+1):\n",
    "    lags=range(step,step + number_of_lags)\n",
    "    draw = 0\n",
    "    print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "    df_list = []\n",
    "    for lag in lags:\n",
    "        number_of_repetitions = number_of_lags+step-lag\n",
    "#        print('lag:',lag,'repetitions:',number_of_repetitions)\n",
    "#        print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "        for repetition in range(1,number_of_repetitions):\n",
    "            lagged_col = 'ged_sb_best_sum_nokgi_' + str(lag)\n",
    "            df = pd.DataFrame(df_cm_historical_values[lagged_col].copy())\n",
    "            df.reset_index(inplace=True)\n",
    "            df['prediction'] = df[lagged_col]\n",
    "#            print(df.head())\n",
    "            df.drop(columns=[lagged_col], inplace=True)\n",
    "            df['step'] = step\n",
    "            df['draw'] = draw\n",
    "            df.set_index(['month_id', 'country_id', 'step','draw'], inplace=True)\n",
    "            df_list.append(df)\n",
    "#            if draw == 1 and step == 1:\n",
    "#                df_cm_predictions_historical_values = df.copy()\n",
    "#            else:\n",
    "#                df_cm_predictions_historical_values = pd.concat([df_cm_predictions_historical_values,df])\n",
    "            draw = draw + 1\n",
    "    df_cm_predictions_lag = pd.concat(df_list)\n",
    "    df_list_bystep.append(df_cm_predictions_lag)\n",
    "    print('Number of draws:',draw + 1)\n",
    "df_cm_predictions_historical_values = pd.concat(df_list_bystep) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cm_predictions_historical_values.describe())\n",
    "print(df_cm_predictions_historical_values.head())\n",
    "print(df_cm_predictions_historical_values.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_historical_values_predictions = from_ss48_to_sc12(df_cm_predictions_historical_values,'cm',445,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_and_categorize(df, level):\n",
    "    ''' This function aggregates the input df across all draws, and returns summary statistics for the prediction model '''\n",
    "    if level == 'cm':\n",
    "        index = ['month_id','country_id']\n",
    "    if level == 'pgm':\n",
    "        index = ['month_id', 'priogrid_gid']\n",
    "    if level == 'pgm2':\n",
    "        index = ['month_id', 'priogrid_id']\n",
    "    df_to_aggregate = df.copy()\n",
    "    df_to_aggregate['log_prediction'] = np.log1p(df_to_aggregate['prediction'] )\n",
    "\n",
    "    # Proportion of draws in fatality categories\n",
    "    #for cutoffs in [0,1,10,100,1000,10000]:\n",
    "    bins = pd.IntervalIndex.from_tuples([(-1, 0), (1, 10), (11, 100), (101, 1000), (1001, 10000), (10001,100000000)])\n",
    "    df_to_aggregate['categorical'] = pd.cut(df_to_aggregate['prediction'],bins)\n",
    "    df_to_aggregate_dummies = pd.get_dummies(df_to_aggregate['categorical'],prefix='cat')\n",
    "    df_to_aggregate = pd.concat([df_to_aggregate,df_to_aggregate_dummies],axis=1)\n",
    "\n",
    "    # Mean and standard deviation of log predictions\n",
    "    df_aggregated = pd.DataFrame(df_to_aggregate['log_prediction'].groupby(level=index).mean())\n",
    "    df_aggregated.rename(columns={'log_prediction':'mean_log_prediction'},inplace=True)\n",
    "    df_aggregated['std_log_prediction'] = df_to_aggregate['log_prediction'].groupby(level=index).std()\n",
    "    for col in ('cat_(-1, 0]','cat_(1, 10]','cat_(11, 100]','cat_(101, 1000]','cat_(1001, 10000]','cat_(10001, 100000000]'):\n",
    "        df_aggregated[col] = df_to_aggregate[col].groupby(level=index).mean()\n",
    "    return(df_aggregated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a2957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across draws/samples to extract means, standard deviations, and category probabilities\n",
    "df_cm_predictions_historical_values_aggregated = aggregate_and_categorize(df_cm_predictions_historical_values,'cm')\n",
    "df_cm_predictions_ensemble_aggregated = aggregate_and_categorize(df_cm_final_extended,'cm')\n",
    "\n",
    "print(df_cm_predictions_historical_values_aggregated.describe())\n",
    "print(df_cm_predictions_historical_values_aggregated.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa3d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Saving the annual sc files and the aggregated versions of them\n",
    "filepath = Mydropbox + 'Prediction_competition_2023/'\n",
    "year = 2018\n",
    "for df in cm_historical_values_predictions:\n",
    "    # Simplifying the indices: removing the step column\n",
    "    print('cm_historical', year)\n",
    "    df = df.reset_index()\n",
    "    df.set_index(['month_id','country_id','draw'],inplace=True)\n",
    "    df.drop(columns=['step'],inplace=True)\n",
    "    df['prediction'] = df['prediction'].astype('int32') \n",
    "    print(df.head())\n",
    "    print(df.dtypes)\n",
    "    filename = filepath + 'bm_cm_historical_values_' + str(year) + '.parquet'\n",
    "    print(filename)\n",
    "    df.to_parquet(filename)\n",
    "    df_aggregated = aggregate_and_categorize(df,'cm')\n",
    "    filename = filepath + 'bm_cm_historical_values_agg' + str(year) + '.parquet'\n",
    "    df_aggregated.to_parquet(filename)\n",
    "    year = year + 1\n",
    "year = 2018\n",
    "for df in cm_ensemble_predictions:\n",
    "    print('cm_ensemble', year)\n",
    "    df = df.reset_index()\n",
    "    df.set_index(['month_id','country_id','draw'],inplace=True)\n",
    "    df.drop(columns=['step'],inplace=True)\n",
    "    df['prediction'] = df['prediction'].astype('int32') \n",
    "    filename = filepath + 'bm_cm_ensemble_' + str(year) + '.parquet'\n",
    "    print(filename)\n",
    "    df.to_parquet(filename)\n",
    "    df_aggregated = aggregate_and_categorize(df,'cm')\n",
    "    filename = filepath + 'bm_cm_ensemble_agg' + str(year) + '.parquet'\n",
    "    df_aggregated.to_parquet(filename)\n",
    "    year = year + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13036c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947356fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "include_expansive = False\n",
    "\n",
    "if include_expansive:\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_actuals.parquet'\n",
    "    cm_actuals.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_22.parquet'\n",
    "    df_cm_results_long_pruned.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_550.parquet'\n",
    "    df_cm_final_extended.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_550_aggregated.parquet'\n",
    "    df_cm_predictions_ensemble_aggregated.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_historical_values.parquet'\n",
    "    df_cm_predictions_historical_values.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_predictions_historical_values_aggregated.parquet'\n",
    "    df_cm_predictions_historical_values_aggregated.to_parquet(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51884343",
   "metadata": {},
   "source": [
    "# pgm level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178e6ae",
   "metadata": {},
   "source": [
    "### Based on ensemble; expanded using a Poisson draw with mean=variance=\\hat{y}_{it}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling benchmark based on VIEWS ensemble predictions\n",
    "sc_predictions_ensemble_pgm = []\n",
    "pgm_ensemble_name = 'pgm_ensemble_cm_calib_test'\n",
    "    \n",
    "ensemble_pgm_df = pd.DataFrame.forecasts.read_store(pgm_ensemble_name, run=dev_id)[stepcols]\n",
    "ensemble_pgm_df.head()\n",
    "\n",
    "for year in year_list[0:3]:\n",
    "    sc_dict = {\n",
    "        'year': year,\n",
    "        'prediction_df': extract_sc_predictions(year=year,ss_predictions=ensemble_pgm_df)\n",
    "    }\n",
    "    sc_predictions_ensemble_pgm.append(sc_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pgm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb07bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding by drawing n draws from Poisson distribution   \n",
    "for year_record in sc_predictions_ensemble_pgm:\n",
    "    print(year_record['year'])\n",
    "    year_record['expanded_df'] = expanded_predictions(sc_predictions = year_record['prediction_df'],draws = draws_pgm, level = 'pgm')\n",
    "\n",
    "describe_expanded(df=sc_predictions_ensemble[0]['prediction_df'], df_expanded=sc_predictions_ensemble[0]['expanded_df'], month=457, country=57)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b14afc",
   "metadata": {},
   "source": [
    "# Old pgm stuff from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea38184",
   "metadata": {},
   "source": [
    "## Ensemble model pgm benchmark\n",
    "\n",
    "kj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e78ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "level = 'pgm'\n",
    "ModelList_pgm = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList_pgm:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1\n",
    "    \n",
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "\n",
    "ModelList_pgm = RetrieveStoredPredictions(ModelList_pgm, steps, EndOfHistory, dev_id, level, get_future)\n",
    "\n",
    "#ModelList_pgm = CalibratePredictions(ModelList_pgm, EndOfHistory, steps)\n",
    "\n",
    "# Dataframe with actuals\n",
    "df_actuals_pgm = pd.DataFrame(ModelList_pgm[0]['predictions_test_df']['ln_ged_sb_dep'])\n",
    "print(df_actuals_pgm.head())\n",
    "print(df_actuals_pgm.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48259249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "def reshape_df_pgm(df, draw):\n",
    "    ''' Drops steps we will not need in the benchmark model. \n",
    "    Another round of drops are done below '''\n",
    "    steps_to_drop = ['ln_ged_sb_dep','step_pred_23','step_pred_24',\n",
    "                     'step_pred_25','step_pred_26','step_pred_27','step_pred_28','step_pred_29','step_pred_30',\n",
    "                     'step_pred_31','step_pred_32','step_pred_33','step_pred_34','step_pred_35','step_pred_36',]\n",
    "    df = df.drop(steps_to_drop,axis=1)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['draw'] = draw\n",
    "    df_long = pd.wide_to_long(df, 'step_pred_', i = ['month_id', 'priogrid_id', 'draw'], j = 'step')\n",
    "    return(df_long)\n",
    "\n",
    "model_draw = 0\n",
    "df = ModelList_pgm[model_draw]['predictions_test_df'].copy()\n",
    "df_pgm_results_long = reshape_df_pgm(df,model_draw)\n",
    "print('Starting with model/draw',model_draw, model['modelname'])\n",
    "print(df_pgm_results_long.describe())\n",
    "\n",
    "\n",
    "for model in ModelList_pgm[1:]:\n",
    "    model_draw += 1\n",
    "    print('Appending model/draw',model_draw, model['modelname'])\n",
    "    df = ModelList_pgm[model_draw]['predictions_test_df'].copy()\n",
    "    df_reshaped = reshape_df_pgm(df,model_draw)\n",
    "    df_pgm_results_long = pd.concat([df_pgm_results_long ,df_reshaped], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_results_long['prediction'] = np.round_(np.expm1(df_pgm_results_long['step_pred_'])).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fcee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_results_long.drop(columns=['step_pred_'], inplace=True)\n",
    "#df_pgm_results_extended.index.set_names('priogrid_gid', level=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results file in long format\n",
    "print(df_pgm_results_long.describe())\n",
    "print(df_pgm_results_long.tail())\n",
    "\n",
    "print(df_pgm_results_long.loc[492].describe())\n",
    "\n",
    "# Extending by copying adjacent steps\n",
    "\n",
    "df_pgm_results_extended=df_pgm_results_long.copy()\n",
    "\n",
    "print(df_pgm_results_extended.describe())\n",
    "print(df_pgm_results_extended.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba44b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into separate files by step\n",
    "df_ensembles_pgm_by_step = []\n",
    "for step in range(3,14+1):\n",
    "    print(step)\n",
    "    df = df_pgm_results_extended.xs(step, level=3).copy()\n",
    "    #print(df.describe())\n",
    "    df_ensembles_pgm_by_step.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4549533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dfcopy_pgm(df_in, step, shifted_step, repetition):\n",
    "    ''' Makes a 'copy' of the df with a shifted step '''\n",
    "#    print(step, shifted_step, repetition)\n",
    "    df = pd.DataFrame(df_in[df_in.index.get_level_values('step').isin([shifted_step])]).copy()\n",
    "    df.reset_index(inplace = True)\n",
    "    df['step'].replace(shifted_step, step, inplace = True)\n",
    "#    print(df.describe())\n",
    "    df['draw'] = (df['draw'] + len(ModelList_pgm) * repetition)\n",
    "#    print(df.describe())\n",
    "    df.set_index(['month_id', 'priogrid_id', 'step', 'draw'], inplace=True)\n",
    "    return(df)\n",
    "\n",
    "for step in range(3,14+1):     \n",
    "    print(80*'*')\n",
    "    print('Step', step, '-- Original dataframe for step', step, 'is:')\n",
    "    df = pd.DataFrame(df_pgm_results_extended[df_pgm_results_extended.index.get_level_values('step').isin([step])])\n",
    "    print(df.describe())\n",
    "    repetition = 1\n",
    "    df_list_pgm = []\n",
    "    for shift in [(-4,1),(-3,1),(-2,3),(-1,4),(0,3),(1,3),(2,2),(3,2),(4,1),(5,1),(6,1),(7,1),(8,1)]:\n",
    "        for copy in range(1,shift[1]+1):\n",
    "            shifted_step = step+shift[0]\n",
    "            if shifted_step < 1:\n",
    "                shifted_step = step\n",
    "            step_list = [shifted_step]\n",
    "            df = make_dfcopy_pgm(df_in = df_pgm_results_extended,step = step, shifted_step = shifted_step, repetition = repetition)\n",
    "            df_list_pgm.append(df)\n",
    "            repetition += 1\n",
    "    df_pgm_temp = pd.concat(df_list_pgm)\n",
    "    print('Extended:')\n",
    "    print(df_pgm_temp.describe())\n",
    "    # Export to parquet\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_ensemble_step_' + str(step) + '.parquet'\n",
    "    df_pgm_temp.to_parquet(filename)\n",
    "    # Aggregate across draws, save    \n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_ensemble_step_' + str(step) + '_aggregated.parquet'\n",
    "    df_aggregated_pgm = aggregate_and_categorize(df_pgm_temp,'pgm2')\n",
    "    print('Aggregated:')\n",
    "    print(df_aggregated_pgm.describe())\n",
    "    df_aggregated_pgm.to_parquet(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sc prediction files for ensemble model\n",
    "pgm_ensemble_predictions = from_ss48_to_sc12(df_pgm_results_extended,'pgm2',445,4)\n",
    "\n",
    "# Saving the annual sc files and the aggregated versions of them\n",
    "filepath = Mydropbox + 'Prediction_competition_2023/'\n",
    "year = 2018\n",
    "for df in pgm_ensemble_predictions:\n",
    "    filename = filepath + 'bm_pgm_ensemble_' + str(year) + '.parquet'\n",
    "    print(filename)\n",
    "    df.to_parquet(filename)\n",
    "    df_aggregated = aggregate_and_categorize(df,'pgm')\n",
    "    filename = filepath + 'bm_pgm_ensemble_agg' + str(year) + '.parquet'\n",
    "    df_aggregated.to_parquet(filename)\n",
    "    year = year + 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be4904",
   "metadata": {},
   "source": [
    "## Historical values pgm benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55417594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag settings (number of temporal lags at each spatial lag level)\n",
    "tlags_cell = 40\n",
    "tlags_firstorder = 27\n",
    "tlags_secondorder = 21\n",
    "\n",
    "# Spatial lags, first-order lag 1:\n",
    "kernel_inner=1\n",
    "kernel_width=1\n",
    "kernel_power=0\n",
    "norm_kernel=0\n",
    "\n",
    "rerun_querysets = False\n",
    "\n",
    "def retrieve_qs(qs_to_retrieve=qs,rerun=True,filename=''):\n",
    "    if rerun:\n",
    "        df = qs_to_retrieve.publish().fetch().loc[445:492]    \n",
    "        df.to_parquet(filename)\n",
    "    else:\n",
    "        df = pd.read_parquet(filename)\n",
    "    return(df)\n",
    "    \n",
    "\n",
    "print('Retrieving data for inner cells')\n",
    "\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_pgm\"\n",
    "\n",
    "qs = (Queryset(\"benchmark_pgm\", \"priogrid_month\")\n",
    "\n",
    "   # target variable at t0\n",
    "   .with_column(Column(\"ged_sb\", from_table=\"ged2_pgm\", from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.fill()\n",
    "                .transform.missing.replace_na()\n",
    "                )\n",
    "    # spatial lag at t0\n",
    "   .with_column(Column(\"splag_ged_sb_0\", from_table = table, from_column = column)\n",
    "                     .transform.missing.replace_na()\n",
    "                     .transform.spatial.lag(kernel_inner,kernel_width,kernel_power,norm_kernel)\n",
    "                    )\n",
    "\n",
    "\n",
    "   .with_theme(\"benchmark\")\n",
    "   .describe(\"\"\"Data for empirical benchmark model, pgm level\n",
    "            \"\"\")\n",
    "   )\n",
    "\n",
    "#queryset = Queryset(\"name\", \"loa\") # if not already defined\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_pgm\"\n",
    "tlags_0=range(1,tlags_cell + 1)\n",
    "qs0 = qs.copy()\n",
    "for lag in tlags_0: \n",
    "    qs0 = qs0.with_column(Column(column + '_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                       )\n",
    "    \n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'df_pgm_historical_values_0.parquet'\n",
    "df_pgm_historical_values_0 = retrieve_qs(qs_to_retrieve=qs0,rerun = rerun_querysets,filename=filename)\n",
    "\n",
    "#if rerun_querysets:\n",
    "#    df_pgm_historical_values_0 = qs0.publish().fetch().loc[445:492]    \n",
    "#    df_pgm_historical_values_0.to_parquet(filename)\n",
    "#else:\n",
    "#    df_pgm_historical_values_0 = pd.read_parquet(filename)\n",
    "\n",
    "# Spatial lags, first-order:\n",
    "print('Retrieving data for first-order neighbors')\n",
    "\n",
    "kernel_inner=1\n",
    "kernel_width=1\n",
    "kernel_power=0\n",
    "norm_kernel=0\n",
    "\n",
    "tlags_1=range(1,tlags_firstorder + 1)\n",
    "qs1 = qs.copy()\n",
    "for lag in tlags_1:\n",
    "    qs1 = qs1.with_column(Column(column + '_splag_1_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                        .transform.spatial.lag(kernel_inner,kernel_width,kernel_power,norm_kernel)\n",
    "                       )\n",
    "\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'df_pgm_historical_values_1.parquet'\n",
    "#df_pgm_historical_values_1 = qs1.publish().fetch().loc[445:492]\n",
    "df_pgm_historical_values_1 = retrieve_qs(qs_to_retrieve=qs1,rerun = rerun_querysets,filename=filename)\n",
    "\n",
    "# Spatial lags; second-order:\n",
    "print('Retrieving data for second-order neighbors')\n",
    "\n",
    "kernel_inner=2\n",
    "kernel_width=1\n",
    "kernel_power=0\n",
    "norm_kernel=0\n",
    "\n",
    "tlags_2=range(1,tlags_secondorder + 1)\n",
    "qs2 = qs.copy()\n",
    "for lag in tlags_2:\n",
    "    qs2 = qs2.with_column(Column(column + '_splag_2_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                        .transform.spatial.lag(kernel_inner,kernel_width,kernel_power,norm_kernel)\n",
    "                       )\n",
    "\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'df_pgm_historical_values_2.parquet'\n",
    "df_pgm_historical_values_2 = retrieve_qs(qs_to_retrieve=qs2,rerun = rerun_querysets,filename=filename)\n",
    "\n",
    "#df_pgm_historical_values_2 = qs2.publish().fetch().loc[445:492]\n",
    "print('Done retrieving data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aabc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_historical_values_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ccd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the data frames\n",
    "df_pgm_historical_values = pd.concat([df_pgm_historical_values_0, df_pgm_historical_values_1, df_pgm_historical_values_2], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_historical_values = df_pgm_historical_values.loc[445:492]\n",
    "# Computing averages from sums\n",
    "for lag in tlags_1:\n",
    "    col = column + '_splag_1_' + str(lag)\n",
    "    df_pgm_historical_values[col] = df_pgm_historical_values[col]\n",
    "for lag in tlags_2:\n",
    "    col = column + '_splag_2_' + str(lag)\n",
    "    df_pgm_historical_values[col] = df_pgm_historical_values[col]\n",
    "\n",
    "\n",
    "\n",
    "df_pgm_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_historical_values_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictions for test partition\n",
    "number_of_lags_inner = 24\n",
    "number_of_lags_1 = 12\n",
    "number_of_lags_2 = 6\n",
    "maxstep = 14\n",
    "df_list_bystep = []\n",
    "for step in range(3,maxstep+1):\n",
    "    lags=range(step,number_of_lags_inner+step)\n",
    "    draw = 1\n",
    "#    print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "    df_list = []\n",
    "    for lag in lags:\n",
    "        for coltype in [('ged_sb_best_sum_nokgi_',number_of_lags_inner),('ged_sb_best_sum_nokgi_splag_1_',number_of_lags_1),('ged_sb_best_sum_nokgi_splag_2_',number_of_lags_2)]:\n",
    "            number_of_repetitions = coltype[1]+step-lag\n",
    "            for repetition in range(1,number_of_repetitions+1):\n",
    "                if lag <= coltype[1] + step:\n",
    "                    lagged_col = coltype[0] + str(lag)\n",
    "#                    print('draw:',draw, 'step:', step, 'lag:',lag,'repetition:', repetition, 'colname:', lagged_col)\n",
    "                    df = pd.DataFrame(df_pgm_historical_values[lagged_col].copy())\n",
    "                    df.reset_index(inplace=True)\n",
    "                    df['prediction'] = df[lagged_col].astype('int32')\n",
    "                    df.drop(columns=[lagged_col], inplace=True)\n",
    "                    df['step'] = step\n",
    "                    df['draw'] = draw\n",
    "                    df.set_index(['month_id', 'priogrid_gid', 'step','draw'], inplace=True)\n",
    "                    df_list.append(df)\n",
    "                    draw = draw + 1\n",
    "    print('Concatenating', draw-1, 'repetitions for step', step)\n",
    "    df_pgm_predictions_lag = pd.concat(df_list)\n",
    "    df_list_bystep.append(df_pgm_predictions_lag)\n",
    "    \n",
    "#df_pgm_predictions_historical_values = pd.concat(df_list_bystep) \n",
    "#df_pgm_predictions_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff56a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_bystep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sc prediction files for historical values model -- step by step\n",
    "step = 3\n",
    "df_sc_bystep = [[],[],[],[]]\n",
    "for step_df in df_list_bystep:\n",
    "    print('step:', step)\n",
    "    pgm_hv_step = from_ss48_to_sc12(step_df,'pgm2',445,4)\n",
    "    per = 0\n",
    "    for period in pgm_hv_step:\n",
    "        df_sc_bystep[per].append(pgm_hv_step[per])\n",
    "        per += 1\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ade91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Aggregating')\n",
    "pgm_historical_values_predictions = [[],[],[],[]]\n",
    "for period in range(0,4):\n",
    "    pgm_historical_values_predictions[period] = pd.concat(df_sc_bystep[period]) \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the annual sc files and the aggregated versions of them\n",
    "filepath = Mydropbox + 'Prediction_competition_2023/'\n",
    "year = 2018\n",
    "for df in pgm_historical_values_predictions:\n",
    "    filename = filepath + 'bm_pgm_historical_values_' + str(year) + '.parquet'\n",
    "    print(filename)\n",
    "    df.to_parquet(filename)\n",
    "    df_aggregated = aggregate_and_categorize(df,'pgm')\n",
    "    filename = filepath + 'bm_pgm_historical_values_agg' + str(year) + '.parquet'\n",
    "    df_aggregated.to_parquet(filename)\n",
    "    year = year + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm_historical_values_predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ec044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating step-level dataframes\n",
    "single_file = False\n",
    "\n",
    "if single_file:\n",
    "    df_pgm_predictions_historical_values = df_list_bystep[0]\n",
    "    list_item = 1\n",
    "    for step in range(3+1,maxstep+1):\n",
    "        print('adding data for step', step)\n",
    "        df_pgm_predictions_historical_values = pd.concat([df_pgm_predictions_historical_values,df_list_bystep[list_item]])\n",
    "        list_item += 1\n",
    "\n",
    "    df_pgm_predictions_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccedd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with actuals\n",
    "df_actuals_pgm = pd.DataFrame(df_pgm_historical_values_0['ged_sb'])\n",
    "print(df_actuals_pgm.head())\n",
    "print(df_actuals_pgm.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_actuals.parquet'\n",
    "df_actuals_pgm.to_parquet(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a3194",
   "metadata": {},
   "source": [
    "# Probably obsolete from here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across draws/samples to extract means, standard deviations, and category probabilities\n",
    "# export to parquet step by step\n",
    "step = 3\n",
    "for df in df_list_bystep:\n",
    "    print(step)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values_step_' + str(step) + '.parquet'\n",
    "    df.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values_step_' + str(step) + '_aggregated.parquet'\n",
    "    df_aggregated = aggregate_and_categorize(df,'pgm')\n",
    "    df_aggregated.to_parquet(filename)\n",
    "\n",
    "    print(df_aggregated.describe())\n",
    "    print(df_aggregated.mean())\n",
    "        \n",
    "    step = step+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d69f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values.parquet'\n",
    "df_from_file = pd.read_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values_step_3.parquet'\n",
    "df_from_file = pd.read_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74afc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
